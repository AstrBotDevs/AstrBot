import asyncio
import time
import traceback
from collections.abc import AsyncGenerator

from astrbot.core import logger
from astrbot.core.agent.message import Message
from astrbot.core.agent.runners.tool_loop_agent_runner import ToolLoopAgentRunner
from astrbot.core.astr_agent_context import AstrAgentContext
from astrbot.core.message.components import Json, Plain
from astrbot.core.message.message_event_result import (
    MessageChain,
    MessageEventResult,
    ResultContentType,
)
from astrbot.core.provider.entities import LLMResponse
from astrbot.core.provider.provider import TTSProvider

AgentRunner = ToolLoopAgentRunner[AstrAgentContext]


async def run_agent(
    agent_runner: AgentRunner,
    max_step: int = 30,
    show_tool_use: bool = True,
    stream_to_general: bool = False,
    show_reasoning: bool = False,
) -> AsyncGenerator[MessageChain | None, None]:
    step_idx = 0
    astr_event = agent_runner.run_context.context.event
    while step_idx < max_step + 1:
        step_idx += 1

        if step_idx == max_step + 1:
            logger.warning(
                f"Agent reached max steps ({max_step}), forcing a final response."
            )
            if not agent_runner.done():
                # æ‹”æ‰æ‰€æœ‰å·¥å…·
                if agent_runner.req:
                    agent_runner.req.func_tool = None
                # æ³¨å…¥æç¤ºè¯
                agent_runner.run_context.messages.append(
                    Message(
                        role="user",
                        content="å·¥å…·è°ƒç”¨æ¬¡æ•°å·²è¾¾åˆ°ä¸Šé™ï¼Œè¯·åœæ­¢ä½¿ç”¨å·¥å…·ï¼Œå¹¶æ ¹æ®å·²ç»æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼Œå¯¹ä½ çš„ä»»åŠ¡å’Œå‘ç°è¿›è¡Œæ€»ç»“ï¼Œç„¶åç›´æ¥å›å¤ç”¨æˆ·ã€‚",
                    )
                )

        try:
            async for resp in agent_runner.step():
                if astr_event.is_stopped():
                    return
                if resp.type == "tool_call_result":
                    msg_chain = resp.data["chain"]
                    if msg_chain.type == "tool_direct_result":
                        # tool_direct_result ç”¨äºæ ‡è®° llm tool éœ€è¦ç›´æ¥å‘é€ç»™ç”¨æˆ·çš„å†…å®¹
                        await astr_event.send(msg_chain)
                        continue
                    if astr_event.get_platform_id() == "webchat":
                        await astr_event.send(msg_chain)
                    # å¯¹äºå…¶ä»–æƒ…å†µï¼Œæš‚æ—¶å…ˆä¸å¤„ç†
                    continue
                elif resp.type == "tool_call":
                    if agent_runner.streaming:
                        # ç”¨æ¥æ ‡è®°æµå¼å“åº”éœ€è¦åˆ†èŠ‚
                        yield MessageChain(chain=[], type="break")

                    if astr_event.get_platform_name() == "webchat":
                        await astr_event.send(resp.data["chain"])
                    elif show_tool_use:
                        json_comp = resp.data["chain"].chain[0]
                        if isinstance(json_comp, Json):
                            m = f"ğŸ”¨ è°ƒç”¨å·¥å…·: {json_comp.data.get('name')}"
                        else:
                            m = "ğŸ”¨ è°ƒç”¨å·¥å…·..."
                        chain = MessageChain(type="tool_call").message(m)
                        await astr_event.send(chain)
                    continue

                if stream_to_general and resp.type == "streaming_delta":
                    continue

                if stream_to_general or not agent_runner.streaming:
                    content_typ = (
                        ResultContentType.LLM_RESULT
                        if resp.type == "llm_result"
                        else ResultContentType.GENERAL_RESULT
                    )
                    astr_event.set_result(
                        MessageEventResult(
                            chain=resp.data["chain"].chain,
                            result_content_type=content_typ,
                        ),
                    )
                    yield
                    astr_event.clear_result()
                elif resp.type == "streaming_delta":
                    chain = resp.data["chain"]
                    if chain.type == "reasoning" and not show_reasoning:
                        # display the reasoning content only when configured
                        continue
                    yield resp.data["chain"]  # MessageChain
            if agent_runner.done():
                # send agent stats to webchat
                if astr_event.get_platform_name() == "webchat":
                    await astr_event.send(
                        MessageChain(
                            type="agent_stats",
                            chain=[Json(data=agent_runner.stats.to_dict())],
                        )
                    )

                break

        except Exception as e:
            logger.error(traceback.format_exc())

            err_msg = f"\n\nAstrBot è¯·æ±‚å¤±è´¥ã€‚\né”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {e!s}\n\nè¯·åœ¨å¹³å°æ—¥å¿—æŸ¥çœ‹å’Œåˆ†äº«é”™è¯¯è¯¦æƒ…ã€‚\n"

            error_llm_response = LLMResponse(
                role="err",
                completion_text=err_msg,
            )
            try:
                await agent_runner.agent_hooks.on_agent_done(
                    agent_runner.run_context, error_llm_response
                )
            except Exception:
                logger.exception("Error in on_agent_done hook")

            if agent_runner.streaming:
                yield MessageChain().message(err_msg)
            else:
                astr_event.set_result(MessageEventResult().message(err_msg))
            return


async def run_live_agent(
    agent_runner: AgentRunner,
    tts_provider: TTSProvider | None = None,
    max_step: int = 30,
    show_tool_use: bool = True,
    show_reasoning: bool = False,
) -> AsyncGenerator[MessageChain | None, None]:
    """Live Mode çš„ Agent è¿è¡Œå™¨ï¼Œæ”¯æŒæµå¼ TTS

    Args:
        agent_runner: Agent è¿è¡Œå™¨
        tts_provider: TTS Provider å®ä¾‹
        max_step: æœ€å¤§æ­¥æ•°
        show_tool_use: æ˜¯å¦æ˜¾ç¤ºå·¥å…·ä½¿ç”¨
        show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹

    Yields:
        MessageChain: åŒ…å«æ–‡æœ¬æˆ–éŸ³é¢‘æ•°æ®çš„æ¶ˆæ¯é“¾
    """
    support_stream = tts_provider.support_stream() if tts_provider else False

    if support_stream:
        logger.info("[Live Agent] ä½¿ç”¨æµå¼ TTSï¼ˆåŸç”Ÿæ”¯æŒ get_audio_streamï¼‰")
    elif tts_provider:
        logger.info(
            f"[Live Agent] ä½¿ç”¨ TTSï¼ˆ{tts_provider.meta().type} "
            "ä½¿ç”¨ get_audioï¼Œå°†ç´¯ç§¯å®Œæ•´æ–‡æœ¬åç”ŸæˆéŸ³é¢‘ï¼‰"
        )

    # æ”¶é›† LLM è¾“å‡º
    llm_stream_chunks: list[MessageChain] = []

    # è¿è¡Œæ™®é€š agent
    async for chain in run_agent(
        agent_runner,
        max_step=max_step,
        show_tool_use=show_tool_use,
        stream_to_general=False,
        show_reasoning=show_reasoning,
    ):
        if chain is not None:
            llm_stream_chunks.append(chain)

    # å¦‚æœæ²¡æœ‰ TTS Providerï¼Œç›´æ¥å‘é€æ–‡æœ¬
    if not tts_provider:
        for chain in llm_stream_chunks:
            yield chain
        return

    # å¤„ç† TTS
    tts_start_time = time.time()
    tts_first_frame_time = 0.0
    first_chunk_received = False

    if support_stream:
        # ä½¿ç”¨æµå¼ TTS
        async for audio_chunk in _process_stream_tts(llm_stream_chunks, tts_provider):
            if not first_chunk_received:
                tts_first_frame_time = time.time() - tts_start_time
                first_chunk_received = True
            yield audio_chunk
    else:
        # ä½¿ç”¨å®Œæ•´éŸ³é¢‘ TTS
        async for audio_chunk in _process_full_tts(llm_stream_chunks, tts_provider):
            if not first_chunk_received:
                tts_first_frame_time = time.time() - tts_start_time
                first_chunk_received = True
            yield audio_chunk
    tts_end_time = time.time()

    # å‘é€ TTS ç»Ÿè®¡ä¿¡æ¯
    try:
        astr_event = agent_runner.run_context.context.event
        if astr_event.get_platform_name() == "webchat":
            tts_duration = tts_end_time - tts_start_time
            await astr_event.send(
                MessageChain(
                    type="tts_stats",
                    chain=[
                        Json(
                            data={
                                "duration": tts_duration,
                                "first_frame_time": tts_first_frame_time,
                            }
                        )
                    ],
                )
            )
    except Exception as e:
        logger.error(f"å‘é€ TTS ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


async def _process_stream_tts(chunks: list[MessageChain], tts_provider):
    """å¤„ç†æµå¼ TTS"""
    text_queue: asyncio.Queue[str | None] = asyncio.Queue()
    audio_queue: asyncio.Queue[bytes | None] = asyncio.Queue()

    # å¯åŠ¨ TTS å¤„ç†ä»»åŠ¡
    tts_task = asyncio.create_task(
        tts_provider.get_audio_stream(text_queue, audio_queue)
    )

    chunk_size = 50  # æ¯ 50 ä¸ªå­—ç¬¦å‘é€ä¸€æ¬¡ç»™ TTS

    try:
        # å–‚æ–‡æœ¬ç»™ TTS
        feed_task = asyncio.create_task(
            _feed_text_to_tts(chunks, text_queue, chunk_size)
        )

        # ä» TTS è¾“å‡ºé˜Ÿåˆ—ä¸­è¯»å–éŸ³é¢‘æ•°æ®
        while True:
            audio_data = await audio_queue.get()

            if audio_data is None:
                break

            # å°†éŸ³é¢‘æ•°æ®å°è£…ä¸º MessageChain
            import base64

            audio_b64 = base64.b64encode(audio_data).decode("utf-8")

            chain = MessageChain(chain=[Plain(audio_b64)], type="audio_chunk")
            yield chain

        await feed_task

    except Exception as e:
        logger.error(f"[Live TTS] æµå¼å¤„ç†å¤±è´¥: {e}", exc_info=True)
        await text_queue.put(None)

    finally:
        try:
            await asyncio.wait_for(tts_task, timeout=5.0)
        except asyncio.TimeoutError:
            logger.warning("[Live TTS] TTS ä»»åŠ¡è¶…æ—¶ï¼Œå¼ºåˆ¶å–æ¶ˆ")
            tts_task.cancel()


async def _feed_text_to_tts(
    chunks: list[MessageChain], text_queue: asyncio.Queue, chunk_size: int
):
    """ä»æ¶ˆæ¯é“¾ä¸­æå–æ–‡æœ¬å¹¶åˆ†å—å‘é€ç»™ TTS"""
    accumulated_text = ""

    try:
        for chain in chunks:
            text = chain.get_plain_text()
            if not text:
                continue

            accumulated_text += text

            # å½“ç´¯ç§¯çš„æ–‡æœ¬è¾¾åˆ°chunk_sizeæ—¶ï¼Œå‘é€ç»™TTS
            while len(accumulated_text) >= chunk_size:
                chunk = accumulated_text[:chunk_size]
                await text_queue.put(chunk)
                accumulated_text = accumulated_text[chunk_size:]

        # å¤„ç†å‰©ä½™æ–‡æœ¬
        if accumulated_text:
            await text_queue.put(accumulated_text)

    finally:
        # å‘é€ç»“æŸæ ‡è®°
        await text_queue.put(None)


async def _process_full_tts(chunks: list[MessageChain], tts_provider):
    """å¤„ç†å®Œæ•´éŸ³é¢‘ TTS"""
    accumulated_text = ""

    try:
        # ç´¯ç§¯æ‰€æœ‰æ–‡æœ¬
        for chain in chunks:
            text = chain.get_plain_text()
            if text:
                accumulated_text += text

        # å¦‚æœæ²¡æœ‰æ–‡æœ¬ï¼Œç›´æ¥è¿”å›
        if not accumulated_text:
            return

        logger.info(f"[Live TTS] ç´¯ç§¯å®Œæ•´æ–‡æœ¬ï¼Œé•¿åº¦: {len(accumulated_text)}")

        # è°ƒç”¨ get_audio ç”Ÿæˆå®Œæ•´éŸ³é¢‘
        audio_path = await tts_provider.get_audio(accumulated_text)

        # è¯»å–éŸ³é¢‘æ–‡ä»¶
        with open(audio_path, "rb") as f:
            audio_data = f.read()

        # å°†éŸ³é¢‘æ•°æ®å°è£…ä¸º MessageChain
        import base64

        audio_b64 = base64.b64encode(audio_data).decode("utf-8")

        chain = MessageChain(chain=[Plain(audio_b64)], type="audio_chunk")
        yield chain

    except Exception as e:
        logger.error(f"[Live TTS] å®Œæ•´éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
